{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, unittest, itertools, numpy as np\n",
    "from nltk.corpus import brown\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  For ease of grading please use the following template for your code.  Replace the DefaultTagger with code for HMM Tagger.  You may add other classes and functions, but please do not remove the existing functions like untag(), evaluate(), etc.  We should be able to simply run all the cells in your script to get the accuracies of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DefaultTagger:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.individual_tag = {}\n",
    "        self.transitional_prob_counter = {}\n",
    "        self.emission_prob_counter = {}\n",
    "        self.transitional_prob = {}\n",
    "        self.emission_prob = {}\n",
    "        \n",
    "    def train(self, tagged_sent):\n",
    "        for sentence in tagged_sent:\n",
    "            prev_tag = '<s>'\n",
    "            for word, tag in sentence:\n",
    "                #Add 1 to the counter of tags\n",
    "                self.individual_tag[tag] = self.individual_tag.get(tag, 0) + 1\n",
    "                \n",
    "                #Add to the transitional probability counter\n",
    "                if prev_tag not in self.transitional_prob_counter.keys():\n",
    "                    self.transitional_prob_counter[prev_tag] = {tag:0}\n",
    "                #if tag not in self.transitional_prob[prev_tag].keys():\n",
    "                    #self.transitional_prob[prev_tag][tag] = 0\n",
    "                self.transitional_prob_counter[prev_tag][tag] = self.transitional_prob_counter[prev_tag].get(tag, 0) + 1\n",
    "                prev_tag = tag  #change the value of preious tag to the next tag\n",
    "                \n",
    "                #Add to the emission probability counter\n",
    "                if word not in self.emission_prob_counter.keys():\n",
    "                    self.emission_prob_counter[word] = {tag:0}\n",
    "                self.emission_prob_counter[word][tag] = self.emission_prob_counter[word].get(tag, 0) + 1\n",
    "        self.convert_to_prob()\n",
    "    \n",
    "    def convert_to_prob(self):\n",
    "        '''\n",
    "        Converts the Transitional and Emission counter to probabilities\n",
    "        '''\n",
    "        self.transitional_prob = copy.deepcopy (self.transitional_prob_counter)\n",
    "        self.emission_prob = copy.deepcopy(self.emission_prob_counter)\n",
    "        for prev in self.transitional_prob:\n",
    "            for pos in self.transitional_prob[prev]:\n",
    "                self.transitional_prob[prev][pos] = self.transitional_prob[prev][pos]/self.individual_tag[prev]\n",
    "        for word in self.emission_prob:\n",
    "            for pos in self.individual_tag:\n",
    "                self.emission_prob[word][pos] = self.emission_prob[word].get(pos, 0)/self.individual_tag[pos]\n",
    "        \n",
    "        \n",
    "    def predict (self, s):\n",
    "        '''\n",
    "        Returns a list of POS for a given test sentence s\n",
    "        '''\n",
    "        #s = ['<s>'] + s\n",
    "        prev = '<s>'\n",
    "        t = len(self.individual_tag.keys())\n",
    "        results = [[1.0, []]]*len(s)*t\n",
    "        for i in range(len(s)):\n",
    "            word = s[i]\n",
    "            j = 0\n",
    "            for tag in self.emission_prob[word]:  #TODO Unseen words\n",
    "                em_prob = self.emission_prob[word][tag]\n",
    "                tran_prob = self.transitional_prob[prev][tag]\n",
    "                prob = em_prob*tran_prob\n",
    "                index = i*t+j\n",
    "                results[index][0] *= prob\n",
    "                results[index][0] *= prob\n",
    "                prev = tag\n",
    "                j =+1\n",
    "                if (j>=t): print ('ALERT!')\n",
    "            \n",
    "        \n",
    "    def tag(self, s):\n",
    "        return list(zip(s, predict(s)))\n",
    "        #return list(zip(s, ['NOUN']*len(s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for (w,t) in tagged_sentence]\n",
    "\n",
    "def evaluate(gold, predicted):\n",
    "    if len(gold) != len(predicted):\n",
    "        raise Exception(\"Mismatching length\")\n",
    "    count = 0\n",
    "    for (g,p) in zip(gold, predicted):\n",
    "        if g[1] == p[1]:\n",
    "            count += 1\n",
    "    l = len(gold)\n",
    "    return(count == l, count, l)\n",
    "\n",
    "def tagger_train(tagger, train):\n",
    "    for ts in train:\n",
    "        tagger.train(ts)\n",
    "\n",
    "def tagger_accuracy(tagger, test):\n",
    "    total_words = 0\n",
    "    total_sentences = len(test)\n",
    "    correct_words = 0\n",
    "    correct_sentences = 0\n",
    "    for ts in test:\n",
    "        pred = tagger.tag(untag(ts))\n",
    "        is_correct, num_correct, total =  evaluate(ts, pred)\n",
    "        if is_correct: \n",
    "            correct_sentences += 1\n",
    "        correct_words += num_correct\n",
    "        total_words += total\n",
    "    return(correct_sentences/total_sentences, correct_words/total_words)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0.0667697063369 Word 0.273498816623\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "max_tag_length = 4\n",
    "# Use smaller values during development and code testing\n",
    "\n",
    "brown_tagged_sents = [s for s in brown.tagged_sents(tagset=\"universal\") if len(s) <= max_tag_length]\n",
    "num_in_fold = len(brown_tagged_sents) // k\n",
    "\n",
    "sentence_accuracies = []\n",
    "word_accuracies = []\n",
    "for i in range(k):\n",
    "    training_set = (brown_tagged_sents[0:i*num_in_fold] + \n",
    "                        brown_tagged_sents[(i+1)*num_in_fold:])\n",
    "    test_set = brown_tagged_sents[i*num_in_fold: (i+1)*num_in_fold]\n",
    "    #\n",
    "    # IN THE FOLLOWING REPLACE THE DefaultTagger() WITH YOUR HMM TAGGER\n",
    "    #\n",
    "    tagger = DefaultTagger()\n",
    "    tagger_train(tagger, training_set)\n",
    "    sentence_accuracy, word_accuracy = tagger_accuracy(tagger, test_set)\n",
    "    sentence_accuracies.append(sentence_accuracy)\n",
    "    word_accuracies.append(word_accuracy)\n",
    "print('Sentence', np.array(sentence_accuracies).mean(), 'Word', np.array(word_accuracies).mean())\n",
    "\n",
    "#\n",
    "# WITH HMM TAGGING YOU SHOULD GET SENTENCE LEVEL ACCURACY OF AT LEAST 0.3, \n",
    "# AND WORD LEVEL ACCURACY OF AT LEAST 0.6.  \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Merger', 'NOUN'), ('proposed', 'VERB')],\n",
       " [('Wards', 'NOUN'), ('protected', 'VERB')],\n",
       " [('Ask', 'VERB'), ('jail', 'NOUN'), ('deputies', 'NOUN')],\n",
       " [('(', '.'), ('2', 'NUM'), (')', '.')],\n",
       " [('Construction', 'NOUN'), ('bonds', 'NOUN')],\n",
       " [('A', 'DET'), ('revolving', 'VERB'), ('fund', 'NOUN')],\n",
       " [('Colquitt', 'NOUN')],\n",
       " [('Austin', 'NOUN'), (',', '.'), ('Texas', 'NOUN')],\n",
       " [('Austin', 'NOUN'), (',', '.'), ('Texas', 'NOUN')],\n",
       " [('Austin', 'NOUN'), (',', '.'), ('Texas', 'NOUN')],\n",
       " [('Austin', 'NOUN'), (',', '.'), ('Texas', 'NOUN')],\n",
       " [('Austin', 'NOUN'), (',', '.'), ('Texas', 'NOUN')],\n",
       " [('Calls', 'VERB'), ('for', 'ADP'), ('extension', 'NOUN')],\n",
       " [('Fears', 'VERB'), ('prejudicial', 'ADJ'), ('aspects', 'NOUN')],\n",
       " [('Washington', 'NOUN'), (',', '.'), ('July', 'NOUN'), ('24', 'NUM')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
